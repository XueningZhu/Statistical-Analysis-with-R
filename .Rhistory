cat('寿命样本: ', samples, '\n')
# 区间估计
# 方法一：按照公式计算
weight_u = mean(samples)
weight_var = sum((samples - weight_u) ^ 2) / (n-1)
spread = qt(1-0.05/2, n-1) * sqrt(weight_var / n)
cat(sprintf('灯泡寿命的置信区间是: [%s, %s]',
round(weight_u - spread, 4),
round(weight_u + spread, 4), '\n'))
# 方法二：使用t.test()计算
interval_2 <- t.test(samples, conf.level = 0.95)$conf.int
cat(sprintf('灯泡寿命的置信区间是: [%s, %s]',
round(interval_2[1], 4),
round(interval_2[2], 4), '\n'))
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = T)
### 数据准备 ###
# 清空工作空间
rm(list = ls())
library(ggplot2)
jobinfo <- read.csv("./data/jobinfo_ch7.csv", fileEncoding = "utf-8")
ggplot(data = jobinfo,aes(x=aveSalary)) +
geom_histogram(binwidth = 2000,fill="gold") +
labs(y="频数",x = "岗位薪资") +
theme_bw() +
theme(panel.border=element_blank(),
text = element_text(family = "STXihei"),
axis.title = element_text(size = 12),
axis.text = element_text(size = 11))
# 利用箱线图画出，学历vs对数平均薪资的分布，箱体的宽度越宽表示样本量越多
# 将学历转化为因子型变量，便于画图
jobinfo$学历要求 = factor(jobinfo$学历要求,levels=c("中专","高中","大专","无","本科","研究生"))
jobinfo$对数薪资 <- log(jobinfo$aveSalary)
# 绘制箱线图
ggplot(jobinfo,aes(学历要求,对数薪资)) +
geom_boxplot(varwidth = TRUE, fill = c(rep("grey",4),rep("gold",2))) +
labs(x="学历要求", y = "对数薪资")+
theme_bw() +
theme(panel.border=element_blank(),
text = element_text(family = "STXihei"),
axis.title = element_text(size = 13),
axis.text = element_text(size = 12))
ggplot(jobinfo,aes(as.factor(Python),对数薪资)) +
geom_boxplot(fill = c("grey","gold")) +
labs(x="是否要求会使用Python", y = "对数薪资") +
theme_bw() +
theme(panel.border=element_blank(),
text = element_text(family = "STXihei"),
axis.title = element_text(size = 15),
axis.text = element_text(size = 14))
ggplot(jobinfo,aes(as.factor(SPSS),对数薪资)) +
geom_boxplot(fill = c("grey","gold")) +
labs(x="是否要求会使用SPSS", y = "对数薪资") +
theme_bw() +
theme(panel.border=element_blank(),
text = element_text(family = "STXihei"),
axis.title = element_text(size = 15),
axis.text = element_text(size = 14))
# 数据预处理
## 转换为factor型变量，地区以河北为基准，公司类别以国企为基准，公司规模以少于50人为基准，学历以无为基准
jobinfo$公司类别 <- factor(jobinfo$公司类别, levels = c("国企","合资","外资","上市公司","民营公司","创业公司"))
jobinfo$公司规模 <- factor(jobinfo$公司规模, levels = c("少于50人","50-500人","500-1000人","1000-5000人","5000-10000人","10000人以上"))
jobinfo$学历要求 <- factor(jobinfo$学历要求, levels = c("无","中专","高中","大专","本科","研究生"))
## 软件要求
for (i in c(2:13)){
jobinfo[,i] <- as.factor(jobinfo[,i])
}
## 建立线性模型
lm.fit1 = lm(aveSalary ~ ., data = jobinfo)
## 查看回归结果
summary(lm.fit1)
## 对线性模型进行回归诊断
# 将画布分为2*2的4块
par(mfrow=c(2,2))
plot(lm.fit1, which = c(1:4))
## 计算对数因变量
jobinfo$对数薪资 <- log(jobinfo$aveSalary)
# 建立对数线性模型，剔除平均薪资变量
lm.fit2 = lm(对数薪资 ~ .-aveSalary, data = jobinfo)
## 使用BIC准则选择模型
n <- nrow(jobinfo)
lm.bic <- step(lm.fit2, direction = "both", k = log(n), trace = F)
summary(lm.bic)
## 新样本
testdata <- data.frame(R = 1, SPSS = 0, Excel = 0, Python = 1, MATLAB = 0, Java = 0, SQL = 1, SAS = 0, Stata = 0, EViews = 0, Spark = 0, Hadoop = 1, 公司类别 = "上市公司", 公司规模 = "1000-5000人", 学历要求 = "研究生", 工作经验 = 3, 地区 = "北上深")
## 将软件技能转换为factor类型
for (i in c(1:12)) {
testdata[,i] <- as.factor(testdata[,i])
}
logsalary_hat <- predict(lm.bic, newdata = testdata)  # 预测值
sigma_hat2 <- sum(lm.bic$residuals^2)/lm.bic$df.residual  # sigma^2估计值
y_hat <- exp(logsalary_hat + sigma_hat2/2)  #
cat("平均薪资水平约为", round(y_hat, 2), "元/月")
# 清除工作环境
cat("\014")
rm(list=ls())
dat0 <- read.csv("./data/house.csv",header=T,fileEncoding = "utf-8") #读入数据
# 处理厅数
n=dim(dat0)[1]
style=rep("其他",n)
style[which(dat0$halls==0)]="无厅"
style[which(dat0$halls>0)]="有厅"
style=factor(style,levels=c("无厅","有厅"))
dat0 <- cbind(dat0,style)
lm1 <- lm(price~CATE+school+subway+style+floor+bedrooms+AREA,data=dat0)
summary(lm1)            #回归结果展示
par(mfrow=c(2,2))           #画2*2的图
plot(lm1,which=c(1:4))      #模型诊断图，存在异方差现象，对因变量取对数
lm2 <- lm(log(price) ~ CATE * school + subway + style + floor + bedrooms + AREA, data = dat0)
summary(lm2)            #回归结果展示
lm3.bic <- step(lm2, k = log(nrow(dat0)), trace = F)
newdata <- data.frame(CATE = "海淀", bedrooms = 2, halls = 1, AREA = 70, floor = "low", subway = 1, school = 1, style = "有厅")
logprice_hat <- predict(lm3.bic, newdata = newdata)  # 预测值
sig_hat2 <- sum(lm3.bic$residuals^2)/lm3.bic$df.residual  # sigma^2估计值
y_hat <- exp(logprice_hat + sig_hat2/2)  #
cat("单位面积房价约为", round(y_hat, 2), "万元/平方米")
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = T)
### 数据准备 ###
# 清空工作空间
rm(list = ls())
## 设置绘图主题
library(ggplot2)
plot_theme_pie <- theme(panel.background = element_rect(fill = rgb(255, 255, 255, maxColorValue = 255)),
plot.background = element_rect(rgb(255, 255, 255, maxColorValue = 255)),
axis.text = element_text(color = rgb(236, 241, 249, maxColorValue = 255)),
panel.grid.major = element_line(color = rgb(236, 241, 249, maxColorValue = 255)),
panel.grid.minor = element_line(color = rgb(236, 241, 249, maxColorValue = 255)),
plot.title = element_text(family = "Hei", face = "bold", size = 14),
legend.title = element_text(family = "Hei", face = "bold",size = 12),
legend.text = element_text(family = "Hei",size = 11))   # 饼图绘制主题
## 设置绘图主题
plot_theme <- theme(panel.background = element_rect(fill = rgb(255, 255, 255, maxColorValue = 255)),
plot.background = element_rect(rgb(255, 255, 255, maxColorValue = 255)),
axis.text = element_text(size = 12,family = "Hei"),
axis.text.x = element_text(size = 12, family = "Hei", face = "bold") ,
axis.text.y = element_text(size = 12, family = "Hei", face = "bold") ,
axis.ticks = element_line(color = rgb(236, 241, 249, maxColorValue = 255)),
axis.title = element_text(size = 13, family = "Hei"),
panel.grid.major = element_line(size = 1),
panel.grid.minor = element_line(color = rgb(236, 241, 249, maxColorValue = 255)),
plot.title = element_text(family = "Hei", face = "bold", size = 14),
legend.title = element_text(family = "Hei", face = "bold",size = 12),
legend.text = element_text(family = "Hei",size = 11))   # 其他图形绘制主题
## 读入数据
descriptive <- read.csv("./data/Data_Cleaning.csv", header = T, stringsAsFactors = F) # 读取原始数据
descriptive <- descriptive[order(descriptive$index_origin),]  # 将数据按照变量index_origin（原始编号）排序
## 调整变量类型
descriptive$offertype[descriptive$offertype %in% c("AD小奖", "Offer", "AD无奖")] <- "Admitted"    # 不考虑奖学金，均归入“Admitted“（录取）
descriptive$offertype[descriptive$offertype == "Rej"] <- "Rejected"
descriptive <- descriptive[ - which(descriptive$offertype == ""),]   # 删去缺失录取结果的样本
## 绘制饼状图
(piechart1 <- ggplot(descriptive, aes(x = factor(1), fill = factor(descriptive$offertype))) +
geom_bar(position = "fill", width = 1) +
scale_fill_manual("申请结果", values = c("grey","gold","skyblue")) +
coord_polar(theta = "y") +
labs(x = "", y = "", title = "\n录取类型") +
plot_theme_pie)
## 修正数据
descriptive$college_apply[descriptive$college_apply %in% c("Texas A", "M University")] <- "Texas A&M University"
descriptive$college_apply[descriptive$college_apply %in% c("Washington University in St", " Louis")] <- "Washington University in St. Louis"
## 统一学校名称
SuoXie <- read.table("./data/美国大学缩写汇总.txt", header = T)  # 读入常见的美国大学缩写汇总
college_apply_new <- NULL                                 # 设置初始值
college_low <- tolower(descriptive$college_apply)         # 不考虑大小写差异（下同）
suoxie_low <- tolower(SuoXie$ysuoxie)
for(i in 1:dim(descriptive)[1]){                          # 统一全称和缩写
if (college_low[i] %in% suoxie_low) {
college_apply_new[i] <- as.character(SuoXie$yquancheng[suoxie_low %in% college_low[i]])
} else college_apply_new[i] <- descriptive$college_apply[i]
}
descriptive$College_apply_new <- college_apply_new        # 统一学校名称后的新变量
## 找出10大热门学校
(top10_college_apply <- names(sort(table(descriptive$College_apply_new),
decreasing = T)[c(1:10)]))
## 为简化后续分析，删掉录取结果为 WaitingList 的样本
descriptive <- descriptive[-which(descriptive$offertype == "WaitingList"),]
## 按学校名称匹配大学排名
universities <- read.table("./data/QS大学排名前百（美国）.txt",header = F, sep="\n")$V1     # 读入QS世界大学排名
top50university <- NULL   # 变量初始化
for(i in 1:dim(descriptive)[1]){
top50university[i] <- descriptive$College_apply_new[i] %in% universities[1:19]  # 共19所美国名校进入世界前五十名
}
## 整理变量
collegerank <- rep("Others",dim(descriptive)[1])
collegerank[top50university] <- "Top50"                      # 大学排名前50
descriptive$CollegeRankTop50 <- collegerank                  # 并入原数据
## gpa标准化
descriptive$Standardgap <- (descriptive$gpa/descriptive$gpa_measure)*4      # 将gpa统一整理为4分制
gpa_offertype <- descriptive[, c("Standardgap", "offertype", "CollegeRankTop50")]
gpa_offertype$offertype <- factor(gpa_offertype$offertype, levels = c("Admitted", "Rejected"),
labels = c("录取","被拒"))                 #  调整因子水平
gpa_offertype$CollegeRankTop50 <- factor(gpa_offertype$CollegeRankTop50, levels = c("Top50","Others"))
## 画图
(boxplot1 <- ggplot(gpa_offertype, aes(x = factor(CollegeRankTop50), y = Standardgap, fill = factor(offertype))) +
geom_boxplot(show.legend = T, varwidth = T) +
scale_fill_manual("申请结果", values = c("grey", "gold")) +    # 按照申请结果填色
scale_y_continuous(limits = c(2, 4),breaks = seq(2, 4, by = 0.2))+     # 不考虑gpa<2.0的样本
labs(x = "申请学校的世界排名", y = "GPA", title = "成绩与申请结果") +
plot_theme)
## 成绩分段
descriptive$gpa_dis <- cut(descriptive$Standardgap, breaks = c(0, 3.4, 3.55, 3.7, Inf),
labels = c("<=3.4", "3.4~3.55", "3.55~3.7", ">3.7"))
## 整理托福成绩
descriptive$toefl <- as.numeric(descriptive$toefl)    # 将托福成绩信息变为数值型
descriptive$toefl_dis <- cut(descriptive$toefl, breaks = c(0, 98, 102, 106, Inf),
labels = c("<=98", "98~102", "102~106", ">106"))
## 计算录取率
ifadmitted <- ifelse(descriptive$offertype == "Admitted",1,0)
admittedPct <- aggregate(ifadmitted, list(descriptive$toefl_dis, descriptive$CollegeRankTop50), mean)
colnames(admittedPct) <- c("TOEFL","学校排名","admittedpct")
admittedPct$学校排名 <- factor(admittedPct$学校排名,levels = c("Top50","Others"))
### 画图
(barplot2 <- ggplot(admittedPct, aes(TOEFL, admittedpct, fill = 学校排名)) +
geom_bar(stat='identity',position='dodge') +
scale_fill_manual("学校排名", values = c("grey", "gold")) +    # 按照申请结果填色
labs(x="", y="", title="\n不同托福成绩的平均录取率") +
geom_text(label = paste(round(admittedPct[order(admittedPct$TOEFL), 3], 2)*100, "%", sep=''),
colour = "black", position = position_dodge(1), size = 3, vjust = - 0.8)  +
geom_hline(aes(yintercept = mean(ifadmitted)), col = "orange", lwd = 1)+
geom_text(label = paste(round(mean(ifadmitted), 2)*100, "%", sep=''),
colour = "orange",x = 5.4, y = 0.7, size = 5.7, vjust =  - 0.5) +
plot_theme)
library(reshape)
## 预处理
descriptive$first <- abs(descriptive$first)
descriptive$sci <- abs(descriptive$sci)
## 录取情况与硬件条件
extra_offertype <- descriptive[, c("rl", "intern", "research", "paper",
"first", "sci", "exchange", "type")]
tab1 <- table(extra_offertype$type)
extra_offertype <- melt(extra_offertype, id = "type")      # 短表变长表
count <- subset(extra_offertype, extra_offertype$value == 1)
tab2 <- table(count$type, count$variable)                  # 申请硕博拥有某硬件条件的情况
count_plot <- melt(rbind(tab2[1, ]/tab1[1], tab2[2, ]/tab1[2],  tab2[3, ]/tab1[3]))  # 学位×硬件条件
count_plot$X1 <- factor(count_plot$X1, levels = c(1, 2, 3),        # 调整变量因子水平
labels = c("MS", "PhD", "混合"))
count_plot$X2 <- factor(count_plot$X2, levels = c("research","paper","first",
"sci","rl","intern","exchange"),
labels = c("科研", "论文", "一作", "SCI论文", "牛推", "实习", "交换"))
## 绘制硬件条件与申请学位的矩阵图
(matrix1 <- ggplot(count_plot, aes(x = X1, y = X2, label = value, fill = value)) + # 画图
geom_tile(show.legend = F) +
geom_text(label = paste(round(count_plot$value, 3)*100, "%", sep = ''),
color = "black", family = "Hei", size = 4.5) +
scale_fill_gradient("count", low = "white", high = "lightCoral") +
labs(x = "申请学位", y = "硬件条件", title = "") + plot_theme)
descriptive$offertype <- as.factor(ifelse(descriptive$offertype=="Admitted", T, F))  # 调整为因子变量
## 回归建模
(formula <- paste0("offertype ~ ",
paste0(c("season","type","cross",colnames(descriptive)[c(26:32,34,36,37)]),collapse = " + ")))
## 抽取训练集
set.seed(123)    # 随机数种子
nsample <- sample(x = dim(descriptive)[1], size = dim(descriptive)[1]/5, replace = F)
## 重新划分训练集和测试集
descriptive_train <- descriptive[-nsample, ]
descriptive_test <- descriptive[nsample, ]
## 建立逻辑回归模型
myglm0 <- glm(formula, family = binomial(), data = descriptive_train)  # 逻辑回归
myglm <- step(myglm0, trace = F)     # AIC准则逐步回归
summary(myglm)    # 查看回归结果
library(pROC)
# 进行预测
pred <- predict(myglm, descriptive_test, type="response")
par(family='STXihei')
# 绘制ROC曲线
plot.roc(descriptive_test$offertype, pred, col = "dodgerblue", print.auc=TRUE,
auc.polygon=TRUE, auc.polygon.col="#f6f6f6", xlab = "FPR",ylab = "TPR", main = "预测ROC曲线")
trainset <- read.csv("./data/sampledata.csv", fileEncoding = "utf-8", header = T)
testset <- read.csv("./data/preddata.csv", fileEncoding = "utf-8", header = T)
summary(trainset)  ## 数据概览
trainset$churn <- as.factor(trainset$churn)  ## 因变量转换为因子型
fit <- glm(churn ~ tenure+expense+degree+tightness+entropy+chgdegree+chgexpense,
family = binomial(link = logit), data = trainset)  ## 拟合逻辑回归模型
summary(fit)  ## 输出模型估计结果
library(pROC)
## 将模型结果应用到新的数据集上
fitted.results <- predict(fit,newdata = testset, type = 'response')
## 绘制ROC曲线 & 计算AUC值
library(ROCR)
testset$churn <- as.factor(testset$churn)
par(family='STXihei')
plot.roc(testset$churn, col = "dodgerblue", print.auc=TRUE,
auc.polygon=TRUE, auc.polygon.col="#f6f6f6", xlab = "特异度",ylab = "敏感度",
fitted.results, main = "预测ROC曲线")
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = T)
### 数据准备 ###
# 清空工作空间
rm(list = ls())
library(psych)
library(readxl)
nba <- read_excel("./data/NBA.xlsx")
predictor <- nba[2:18]
## 变量间相关系数
M <- cor(predictor)
par(family='STXihei')
corrplot::corrplot(M, tl.srt = 60,tl.col = "black")
## 主成分分析选择因子数目
par(family='STXihei')
result1 <- scree(predictor, factors = F, pc = T,  main = "主成分分析崖底碎石图", hline = -1)
## 计算累计方差贡献率
cumvar <- round(cumsum(result1$pcv)/sum(result1$pcv),2)
cat('前三个主成分累计方差贡献率为：', cumvar[1:3])
## 提取主成分
pc <- principal(predictor, nfactors = 3)
pc
round(unclass(pc$weights), 2)  # 计算主成分得分系数
## 计算主成分得分
pc <- principal(predictor, nfactors = 3, scores = TRUE)
head(pc$scores)
## 因子分析
cov <- cov(nba[,2:18])
## 转换为相关系数矩阵（等价于标准化后数据的协方差矩阵）
cor <- cov2cor(cov)
## 选择因子数目
par(family='STXihei')
result2 <- scree(cor, factors = T, pc = F, main="因子分析崖底碎石图", hline = -1)
## 提取公共因子
fa(cor, n.obs = 2448, nfactors = 3, rotate = "none", fm = "ml")
## 因子旋转
fa <- fa(cor, n.obs = 2448, nfactors = 3, rotate = "varimax", fm = "ml")
fa
my_score <- factor.scores(nba[,2:18], fa, method="Bartlett")
head(my_score$scores)
round(fa$weights,2)  # 因子得分权重
## 3个公因子可视化因子得分
fa1 <- fa(cor, n.obs = 2448, nfactors = 3, rotate = "varimax", fm = "ml")
my_score <- factor.scores(nba[,2:18], fa1, method="Bartlett")
s <- data.frame(my_score$scores)
library(psych)
my_cov <- Harman23.cor$cov
## 主成分分析选择因子数目
par(family='STXihei')
hw1 <- scree(my_cov, factors = F, pc = T,  main = "主成分分析崖底碎石图", hline = -1)
## 提取主成分
pc <- principal(my_cov, nfactors = 2)
pc
USpredictor <- USJudgeRatings[, -1]
## 主成分分析选择因子数目
par(family='STXihei')
hw2 <- scree(USpredictor, factors = F, pc = T,  main = "主成分分析崖底碎石图", hline = -1)
pc2 <- principal(USpredictor, nfactors = 1, scores = T)
pc2
head(pc2$scores)
cov_hw3 <- ability.cov$cov
corr <- cov2cor(cov_hw3)
## 选择因子数目
par(family='STXihei')
result2 <- scree(corr, factors = T, pc = F, main="因子分析崖底碎石图", hline = -1)
## 提取公共因子
fa_hw2 <- fa(corr, n.obs = ability.cov$n.obs, nfactors = 2, rotate = "none", fm = "ml")
fa_hw2
## 因子旋转
farot_hw2 <- fa(corr, n.obs = ability.cov$n.obs, nfactors = 2, rotate = "varimax", fm = "ml")
farot_hw2
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = T)
### 数据准备 ###
# 清空工作空间
rm(list = ls())
library(psych)
library(readxl)
nba <- read_excel("./data/NBA.xlsx")
predictor <- nba[2:18]
## 变量间相关系数
M <- cor(predictor)
par(family='STXihei')
corrplot::corrplot(M, tl.srt = 60,tl.col = "black")
## 主成分分析选择因子数目
par(family='STXihei')
result1 <- scree(predictor, factors = F, pc = T,  main = "主成分分析崖底碎石图", hline = -1)
## 计算累计方差贡献率
cumvar <- round(cumsum(result1$pcv)/sum(result1$pcv),2)
cat('前三个主成分累计方差贡献率为：', cumvar[1:3])
## 提取主成分
pc <- principal(predictor, nfactors = 3)
pc
round(unclass(pc$weights), 2)  # 计算主成分得分系数
## 计算主成分得分
pc <- principal(predictor, nfactors = 3, scores = TRUE)
head(pc$scores)
## 因子分析
cov <- cov(nba[,2:18])
## 转换为相关系数矩阵（等价于标准化后数据的协方差矩阵）
cor <- cov2cor(cov)
## 选择因子数目
par(family='STXihei')
result2 <- scree(cor, factors = T, pc = F, main="因子分析崖底碎石图", hline = -1)
## 提取公共因子
fa(cor, n.obs = 2448, nfactors = 3, rotate = "none", fm = "ml")
## 因子旋转
fa <- fa(cor, n.obs = 2448, nfactors = 3, rotate = "varimax", fm = "ml")
fa
my_score <- factor.scores(nba[,2:18], fa, method="Bartlett")
head(my_score$scores)
round(fa$weights,2)  # 因子得分权重
## 3个公因子可视化因子得分
fa1 <- fa(cor, n.obs = 2448, nfactors = 3, rotate = "varimax", fm = "ml")
my_score <- factor.scores(nba[,2:18], fa1, method="Bartlett")
s <- data.frame(my_score$scores)
library(psych)
my_cov <- Harman23.cor$cov
## 主成分分析选择因子数目
par(family='STXihei')
hw1 <- scree(my_cov, factors = F, pc = T,  main = "主成分分析崖底碎石图", hline = -1)
## 提取主成分
pc <- principal(my_cov, nfactors = 2)
pc
USpredictor <- USJudgeRatings[, -1]
## 主成分分析选择因子数目
par(family='STXihei')
hw2 <- scree(USpredictor, factors = F, pc = T,  main = "主成分分析崖底碎石图", hline = -1)
pc2 <- principal(USpredictor, nfactors = 1, scores = T)
pc2
head(pc2$scores)
cov_hw3 <- ability.cov$cov
corr <- cov2cor(cov_hw3)
## 选择因子数目
par(family='STXihei')
result2 <- scree(corr, factors = T, pc = F, main="因子分析崖底碎石图", hline = -1)
## 提取公共因子
fa_hw2 <- fa(corr, n.obs = ability.cov$n.obs, nfactors = 2, rotate = "none", fm = "ml")
fa_hw2
## 因子旋转
farot_hw2 <- fa(corr, n.obs = ability.cov$n.obs, nfactors = 2, rotate = "varimax", fm = "ml")
farot_hw2
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = T)
### 数据准备 ###
# 清空工作空间
rm(list = ls())
# 载入相关包及设定路径
library(plyr)
library(dplyr)
library(stringr)
library(tidyr)
library(corrplot)
library(ggplot2)
library(zoo)
library(reshape2)
library(plotly)
Sys.setlocale("LC_ALL", "zh_cn.utf-8")
# 读入数据
novel = read.csv('./data/novel.csv', fileEncoding = "UTF-8")
# 数据查看与异常处理
head(novel)
# 对小说数据的若干列使用summary()函数
summary(novel[, 2:4])
# 利用group_by()函数对小说按照小说类型分类
novel.小说类型 = novel %>% group_by(小说类型)
# 制作分组统计表
novel.小说类型 %>% summarise(平均评分 = mean(评分), 最大评论数 = max(评论数))
## 饼图 ##
## step 1: 统计频数（此处也可使用table()），即统计出来每一类别的频数。
df1 = ddply(novel, .(小说类别), nrow)
setwd("~/Desktop/renyimeng/RUC硕士/2020FALL/统计基础")
library(Hmisc)
library(data.table)
library(reshape2)
library(magrittr)
library(ggplot2)
# 读入数据
d <- mdb.get("FoodMart.mdb")
# 由于不需要与顾客相关的信息，这里直接在筛选表时就排除顾客相关的变量
sale_fact_97 <- data.table(d$sales_fact_1997[, c("product.id", "store.id", "promotion.id", "unit.sales")])
View(sale_fact_97)
# 由于不需要与顾客相关的信息，这里直接在筛选表时就排除顾客相关的变量
sale_fact_97 <- data.table(d$sales_fact_1997)
View(sale_fact_97)
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = T)
### 数据准备 ###
# 清空工作空间
rm(list = ls())
# 载入相关包及设定路径
library(plyr)
library(dplyr)
library(stringr)
library(tidyr)
library(corrplot)
library(ggplot2)
library(zoo)
library(reshape2)
library(plotly)
Sys.setlocale("LC_ALL", "zh_cn.utf-8")
# 读入数据
novel = read.csv('./data/novel.csv', fileEncoding = "UTF-8")
# 数据查看与异常处理
head(novel)
# 对小说数据的若干列使用summary()函数
summary(novel[, 2:4])
# 利用group_by()函数对小说按照小说类型分类
novel.小说类型 = novel %>% group_by(小说类型)
# 制作分组统计表
novel.小说类型 %>% summarise(平均评分 = mean(评分), 最大评论数 = max(评论数))
# 将小说类型进行简要合并
novel$'小说类别' = "其他"
novel$'小说类别'[novel$小说类型 == "都市小说" | novel$小说类型 == "职场小说"] = "都市类小说"
novel$'小说类别'[novel$小说类型 == "科幻小说" | novel$小说类型 == "玄幻小说" | novel$小说类型 == "奇幻小说"] = "幻想类小说"
novel$'小说类别'[novel$小说类型 == "武侠小说" | novel$小说类型 == "仙侠小说"] = "武侠类小说"
# 求出每一类所占百分比
ratio = table(novel$'小说类别') / sum(table(novel$'小说类别')) * 100
# 定义标签
label1 = names(ratio)
label2 = paste0(round(ratio, 2), "%")
# 去掉异常值
chara = sort(novel$总字数/10000)[1:1500]
## 定性与定量变量--分组箱线图 ##
# 不同性质的小说总点击数和评论数有差别吗
novel_ = novel %>%
dplyr::filter((小说性质 == '公众作品')|(小说性质 == 'VIP作品')) %>%
mutate(小说性质=factor(小说性质))
## 两个定量变量--散点图 ##
# 去除较大的异常值后画图
test = novel[novel$评论数 < 8000 & novel$总点击数 < 200000, ]
x = test$总点击数
y = test$评论数
