(matrix1 <- ggplot(count_plot, aes(x = X1, y = X2, label = value, fill = value)) + # 画图
geom_tile(show.legend = F) +
geom_text(label = paste(round(count_plot$value, 3)*100, "%", sep = ''),
color = "black", family = "Hei", size = 4.5) +
scale_fill_gradient("count", low = "white", high = "lightCoral") +
labs(x = "申请学位", y = "硬件条件", title = "") + plot_theme)
descriptive$offertype <- as.factor(ifelse(descriptive$offertype=="Admitted", T, F))  # 调整为因子变量
## 回归建模
(formula <- paste0("offertype ~ ",
paste0(c("season","type","cross",colnames(descriptive)[c(26:32,34,36,37)]),collapse = " + ")))
## 抽取训练集
set.seed(123)    # 随机数种子
nsample <- sample(x = dim(descriptive)[1], size = dim(descriptive)[1]/5, replace = F)
## 重新划分训练集和测试集
descriptive_train <- descriptive[-nsample, ]
descriptive_test <- descriptive[nsample, ]
## 建立逻辑回归模型
myglm0 <- glm(formula, family = binomial(), data = descriptive_train)  # 逻辑回归
myglm <- step(myglm0, trace = F)     # AIC准则逐步回归
summary(myglm)    # 查看回归结果
library(pROC)
# 进行预测
pred <- predict(myglm, descriptive_test, type="response")
par(family='STXihei')
# 绘制ROC曲线
plot.roc(descriptive_test$offertype, pred, col = "dodgerblue", print.auc=TRUE,
auc.polygon=TRUE, auc.polygon.col="#f6f6f6", xlab = "FPR",ylab = "TPR", main = "预测ROC曲线")
trainset <- read.csv("./data/sampledata.csv", fileEncoding = "utf-8", header = T)
testset <- read.csv("./data/preddata.csv", fileEncoding = "utf-8", header = T)
summary(trainset)  ## 数据概览
trainset$churn <- as.factor(trainset$churn)  ## 因变量转换为因子型
fit <- glm(churn ~ tenure+expense+degree+tightness+entropy+chgdegree+chgexpense,
family = binomial(link = logit), data = trainset)  ## 拟合逻辑回归模型
summary(fit)  ## 输出模型估计结果
library(pROC)
## 将模型结果应用到新的数据集上
fitted.results <- predict(fit,newdata = testset, type = 'response')
## 绘制ROC曲线 & 计算AUC值
library(ROCR)
testset$churn <- as.factor(testset$churn)
par(family='STXihei')
plot.roc(testset$churn, col = "dodgerblue", print.auc=TRUE,
auc.polygon=TRUE, auc.polygon.col="#f6f6f6", xlab = "特异度",ylab = "敏感度",
fitted.results, main = "预测ROC曲线")
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = T)
### 数据准备 ###
# 清空工作空间
rm(list = ls())
library(psych)
library(readxl)
nba <- read_excel("./data/NBA.xlsx")
predictor <- nba[2:18]
## 变量间相关系数
M <- cor(predictor)
par(family='STXihei')
corrplot::corrplot(M, tl.srt = 60,tl.col = "black")
## 主成分分析选择因子数目
par(family='STXihei')
result1 <- scree(predictor, factors = F, pc = T,  main = "主成分分析崖底碎石图", hline = -1)
## 计算累计方差贡献率
cumvar <- round(cumsum(result1$pcv)/sum(result1$pcv),2)
cat('前三个主成分累计方差贡献率为：', cumvar[1:3])
## 提取主成分
pc <- principal(predictor, nfactors = 3)
pc
round(unclass(pc$weights), 2)  # 计算主成分得分系数
## 计算主成分得分
pc <- principal(predictor, nfactors = 3, scores = TRUE)
head(pc$scores)
## 因子分析
cov <- cov(nba[,2:18])
## 转换为相关系数矩阵（等价于标准化后数据的协方差矩阵）
cor <- cov2cor(cov)
## 选择因子数目
par(family='STXihei')
result2 <- scree(cor, factors = T, pc = F, main="因子分析崖底碎石图", hline = -1)
## 提取公共因子
fa(cor, n.obs = 2448, nfactors = 3, rotate = "none", fm = "ml")
## 因子旋转
fa <- fa(cor, n.obs = 2448, nfactors = 3, rotate = "varimax", fm = "ml")
fa
my_score <- factor.scores(nba[,2:18], fa, method="Bartlett")
head(my_score$scores)
round(fa$weights,2)  # 因子得分权重
## 3个公因子可视化因子得分
fa1 <- fa(cor, n.obs = 2448, nfactors = 3, rotate = "varimax", fm = "ml")
my_score <- factor.scores(nba[,2:18], fa1, method="Bartlett")
s <- data.frame(my_score$scores)
library(psych)
my_cov <- Harman23.cor$cov
## 主成分分析选择因子数目
par(family='STXihei')
hw1 <- scree(my_cov, factors = F, pc = T,  main = "主成分分析崖底碎石图", hline = -1)
## 提取主成分
pc <- principal(my_cov, nfactors = 2)
pc
USpredictor <- USJudgeRatings[, -1]
## 主成分分析选择因子数目
par(family='STXihei')
hw2 <- scree(USpredictor, factors = F, pc = T,  main = "主成分分析崖底碎石图", hline = -1)
pc2 <- principal(USpredictor, nfactors = 1, scores = T)
pc2
head(pc2$scores)
cov_hw3 <- ability.cov$cov
corr <- cov2cor(cov_hw3)
## 选择因子数目
par(family='STXihei')
result2 <- scree(corr, factors = T, pc = F, main="因子分析崖底碎石图", hline = -1)
## 提取公共因子
fa_hw2 <- fa(corr, n.obs = ability.cov$n.obs, nfactors = 2, rotate = "none", fm = "ml")
fa_hw2
## 因子旋转
farot_hw2 <- fa(corr, n.obs = ability.cov$n.obs, nfactors = 2, rotate = "varimax", fm = "ml")
farot_hw2
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = T)
### 数据准备 ###
# 清空工作空间
rm(list = ls())
library(psych)
library(readxl)
nba <- read_excel("./data/NBA.xlsx")
predictor <- nba[2:18]
## 变量间相关系数
M <- cor(predictor)
par(family='STXihei')
corrplot::corrplot(M, tl.srt = 60,tl.col = "black")
## 主成分分析选择因子数目
par(family='STXihei')
result1 <- scree(predictor, factors = F, pc = T,  main = "主成分分析崖底碎石图", hline = -1)
## 计算累计方差贡献率
cumvar <- round(cumsum(result1$pcv)/sum(result1$pcv),2)
cat('前三个主成分累计方差贡献率为：', cumvar[1:3])
## 提取主成分
pc <- principal(predictor, nfactors = 3)
pc
round(unclass(pc$weights), 2)  # 计算主成分得分系数
## 计算主成分得分
pc <- principal(predictor, nfactors = 3, scores = TRUE)
head(pc$scores)
## 因子分析
cov <- cov(nba[,2:18])
## 转换为相关系数矩阵（等价于标准化后数据的协方差矩阵）
cor <- cov2cor(cov)
## 选择因子数目
par(family='STXihei')
result2 <- scree(cor, factors = T, pc = F, main="因子分析崖底碎石图", hline = -1)
## 提取公共因子
fa(cor, n.obs = 2448, nfactors = 3, rotate = "none", fm = "ml")
## 因子旋转
fa <- fa(cor, n.obs = 2448, nfactors = 3, rotate = "varimax", fm = "ml")
fa
my_score <- factor.scores(nba[,2:18], fa, method="Bartlett")
head(my_score$scores)
round(fa$weights,2)  # 因子得分权重
## 3个公因子可视化因子得分
fa1 <- fa(cor, n.obs = 2448, nfactors = 3, rotate = "varimax", fm = "ml")
my_score <- factor.scores(nba[,2:18], fa1, method="Bartlett")
s <- data.frame(my_score$scores)
library(psych)
my_cov <- Harman23.cor$cov
## 主成分分析选择因子数目
par(family='STXihei')
hw1 <- scree(my_cov, factors = F, pc = T,  main = "主成分分析崖底碎石图", hline = -1)
## 提取主成分
pc <- principal(my_cov, nfactors = 2)
pc
USpredictor <- USJudgeRatings[, -1]
## 主成分分析选择因子数目
par(family='STXihei')
hw2 <- scree(USpredictor, factors = F, pc = T,  main = "主成分分析崖底碎石图", hline = -1)
pc2 <- principal(USpredictor, nfactors = 1, scores = T)
pc2
head(pc2$scores)
cov_hw3 <- ability.cov$cov
corr <- cov2cor(cov_hw3)
## 选择因子数目
par(family='STXihei')
result2 <- scree(corr, factors = T, pc = F, main="因子分析崖底碎石图", hline = -1)
## 提取公共因子
fa_hw2 <- fa(corr, n.obs = ability.cov$n.obs, nfactors = 2, rotate = "none", fm = "ml")
fa_hw2
## 因子旋转
farot_hw2 <- fa(corr, n.obs = ability.cov$n.obs, nfactors = 2, rotate = "varimax", fm = "ml")
farot_hw2
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = T)
### 数据准备 ###
# 清空工作空间
rm(list = ls())
# 载入相关包及设定路径
library(plyr)
library(dplyr)
library(stringr)
library(tidyr)
library(corrplot)
library(ggplot2)
library(zoo)
library(reshape2)
library(plotly)
Sys.setlocale("LC_ALL", "zh_cn.utf-8")
# 读入数据
novel = read.csv('./data/novel.csv', fileEncoding = "UTF-8")
# 数据查看与异常处理
head(novel)
# 对小说数据的若干列使用summary()函数
summary(novel[, 2:4])
# 利用group_by()函数对小说按照小说类型分类
novel.小说类型 = novel %>% group_by(小说类型)
# 制作分组统计表
novel.小说类型 %>% summarise(平均评分 = mean(评分), 最大评论数 = max(评论数))
## 饼图 ##
## step 1: 统计频数（此处也可使用table()），即统计出来每一类别的频数。
df1 = ddply(novel, .(小说类别), nrow)
setwd("~/Desktop/renyimeng/RUC硕士/2020FALL/统计基础")
library(Hmisc)
library(data.table)
library(reshape2)
library(magrittr)
library(ggplot2)
# 读入数据
d <- mdb.get("FoodMart.mdb")
# 由于不需要与顾客相关的信息，这里直接在筛选表时就排除顾客相关的变量
sale_fact_97 <- data.table(d$sales_fact_1997[, c("product.id", "store.id", "promotion.id", "unit.sales")])
View(sale_fact_97)
# 由于不需要与顾客相关的信息，这里直接在筛选表时就排除顾客相关的变量
sale_fact_97 <- data.table(d$sales_fact_1997)
View(sale_fact_97)
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = T)
### 数据准备 ###
# 清空工作空间
rm(list = ls())
# 载入相关包及设定路径
library(plyr)
library(dplyr)
library(stringr)
library(tidyr)
library(corrplot)
library(ggplot2)
library(zoo)
library(reshape2)
library(plotly)
Sys.setlocale("LC_ALL", "zh_cn.utf-8")
# 读入数据
novel = read.csv('./data/novel.csv', fileEncoding = "UTF-8")
# 数据查看与异常处理
head(novel)
# 对小说数据的若干列使用summary()函数
summary(novel[, 2:4])
# 利用group_by()函数对小说按照小说类型分类
novel.小说类型 = novel %>% group_by(小说类型)
# 制作分组统计表
novel.小说类型 %>% summarise(平均评分 = mean(评分), 最大评论数 = max(评论数))
# 将小说类型进行简要合并
novel$'小说类别' = "其他"
novel$'小说类别'[novel$小说类型 == "都市小说" | novel$小说类型 == "职场小说"] = "都市类小说"
novel$'小说类别'[novel$小说类型 == "科幻小说" | novel$小说类型 == "玄幻小说" | novel$小说类型 == "奇幻小说"] = "幻想类小说"
novel$'小说类别'[novel$小说类型 == "武侠小说" | novel$小说类型 == "仙侠小说"] = "武侠类小说"
# 求出每一类所占百分比
ratio = table(novel$'小说类别') / sum(table(novel$'小说类别')) * 100
# 定义标签
label1 = names(ratio)
label2 = paste0(round(ratio, 2), "%")
# 去掉异常值
chara = sort(novel$总字数/10000)[1:1500]
## 定性与定量变量--分组箱线图 ##
# 不同性质的小说总点击数和评论数有差别吗
novel_ = novel %>%
dplyr::filter((小说性质 == '公众作品')|(小说性质 == 'VIP作品')) %>%
mutate(小说性质=factor(小说性质))
## 两个定量变量--散点图 ##
# 去除较大的异常值后画图
test = novel[novel$评论数 < 8000 & novel$总点击数 < 200000, ]
x = test$总点击数
y = test$评论数
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
rm(list = ls())#清空环境
movie <- read.csv("./data/top250.csv",fileEncoding = "gbk")#读取数据
head(movie)#电影数据示例
class(movie$score)#查看数据类型
#自己为变量附一个数值
a=2;class(a)
exp(1000)  # 正无穷
-10 / 0  # 负无穷
exp(1000) / exp(990)  # NaN类型
exp(10)
#字符的定义
a = "2"
class(a)
# 判断电影数据集中，变量“类型(type)","电影名称(name)"是不是字符型变量
class(movie$name)
class(movie$type)
# 读入数据时设置把字符数据保留，不转换为factor
movie = read.csv("./data/top250.csv", header = T, stringsAsFactors = F, fileEncoding = "gbk")
movie$type[movie$name == "霸王别姬"] == "爱情"
# 想在数据集中挑选大于9分的喜剧电影名称（name）？
movie$name[movie$type == "喜剧" & movie$score > 9]
# 逻辑语句加减
(1 == 2) + (3 < 4)
## 1.什么是因子型数据 ##
(genders = factor(c("男", "女", "女", "男", "男")))#生成因子型变量
(class = factor(c("Poor", "Improved", "Excellent"), ordered = T))#设置因子水平高低
## 2.改变因子型数据各水平的编码顺序 ##
(class = factor(c("Poor", "Improved", "Excellent"), ordered = T,
levels = c("Poor", "Improved", "Excellent")))
## 3.因子型和字符型数据互相转换 ##
# 输入原始字符变量
all = c("男", "女", "女", "男", "男")
# 将字符型变量变成因子型
gender = as.factor(all)
# 变换后的数据类型
is.factor(gender)
class(gender)#判断gender的数据类型
rm(list = ls())#清理工作空间
movie = read.csv("./data/top250.csv",fileEncoding = "gbk",stringsAsFactors = FALSE)#导入数据
## (1)向量创建##
c(1, 1, 1, 2, 3, 3, 1, 2, 4, 1, 2, 4, 4, 2, 3, 4, 1, 2, 3, 4)
c("a", "b", "c", "d")
# seq(起始值, 终止值, 步长)
seq(0, 10, by = 2)#生产0-10之间以2为间隔的等差数列
1:10#生成1—10的连续数列
##(2)向量索引##
x<-c(1, 1, 1, 2, 3, 3)#生成向量
x[5]# 引用x向量中的第5个元素
which(x == 3)#查看x向量中3所在的位置
which.max(x)#查看x向量中最大值所在的位置
which.min(x)#查看x向量中最小值所在的位置
##(3)集合运算##
intersect(c(1, 2, 3, 3, 12, 4, 123, 12), c(1, 2, 3))#求交集
union(c("狗熊会", "聚数据英才"), c("狗熊会", "助产业振兴"))#求并集
setdiff(10:2, 5:3)#求差集
## 数值型向量 ##
x<-c(10,6,4,7,8)#创建数值向量
min(x)#求最小值
max(x)#求最大值
range(x)#求范围
# match函数
x <- c(1, 1, 1, 2, 3, 3, 1, 2, 4, 1, 2, 4, 4, 2, 3, 4, 1, 2, 3, 4)
(y <- letters[x]) # letters是一个内置字符串，里面储存26个字母字符
match(y, letters[1:4])
x <- c("a", "c", "g", "h")
letters
match(x, letters)
# cut函数
(Age = c(72,21,39,74,62,76,64,43,94,44,87,43,42,35,39,46,45,33,24,38))#生成向量
# 将年龄数据离散化
label = c('青年', '中年', '老年')  #设置标签
(ages = cut(Age, breaks = c(20, 35, 50, 100), labels = label))#划分区间
# sort和order函数
(x = c(1,5,4,6,7))#生成向量
sort(x)
order(x)
x[order(x)]
# nchar用来提取字符串的长度
nchar("欢迎关注狗熊会")
# 看看数据集中的电影名字的长度分别是多少
nchar(movie$name)
# 中英文的字符长度计算方法有不同
nchar("Welcome to follow the CluBear")
# substr提取子字符串
substr("欢迎关注狗熊会", 1, 4)
substr("一懒众衫小", 3, 5)
# paste基本玩法
paste(c("双11", "是个", "什么节日"), collapse = "")
paste("A", 1:4)
# paste花式玩法
paste(1:4, collapse = "")
paste(1:4, sep="")
paste("A", 1:4, sep="_")
txt = c("狗熊会", "CluBear", "双11", "生日")
# 返回含有关键字的字符位置
grep("Bear", txt)
gsub("生日", "happy birthday", txt)
# grep返回movie的director中包含“青春”的行号2，movie[2, ]即提取出movie数据集的第2行
(index <- grep("陈凯歌", movie$director))
(cmovie <- movie[index, ])
salary = c("22万", "30万", "50万", "120万", "11万")
(salary0 = gsub("万", "0000", salary))
mean(as.numeric(salary0))
median(as.numeric(salary0))  # 结果是科学计数法的形式
##(1)创建##
# 生成全部是0的矩阵
(zero = matrix(1:9, nrow = 3, ncol = 3))
# 生成一个对角全是1的矩阵,直接在diag中输入对角线向量即可
(dig14 = diag(rep(1, 4)))
##(2)创建##
# 从已有数据转化成矩阵
(M = matrix(1:12, nrow = 3, ncol = 4))
# 生成指定对角元素的对角矩阵
(N = diag(1:4))
## 矩阵概览 ##
# 查看矩阵的维度
dim(M)
# 提取矩阵的行数
nrow(M)
# 提取矩阵的列数
ncol(M)
##  [1] 4
# 引用元素
M[1, 2]
M[1:2, 2:3]
# 给行列命名
colnames(M) = paste("x_", 1:4)
rownames(M) = 1:3; M
# 同样的命令可调用行列名
colnames(M)
rownames(M)
# 将多个矩阵合并
(A = matrix(1:9, nrow = 3, ncol = 3, byrow = T))
(B = diag(11:13))
rbind(A, B)
cbind(A, B)
A + B #矩阵的加法
A - B #矩阵的减法
A * B #矩阵各元素对应相乘
A %*% B #矩阵的乘法
solve(B) #矩阵B的逆
eigen(B) #矩阵B的特征值
##1.创建及引用##
# 创建数组
(result <- array(1:18,dim=c(3,3,2),dimnames = list(c("r1","r2","r3"),c("c1","c2","c3"),c("h1","h2"))))
result[1,2,2]#获取单个元素
result[1,,] #获取第一维度的数据
##2. 操作数组元素##
matrix1<-result[,,1]#获取数组中第1水平的矩阵
matrix2<-result[,,2]#获取数组中第2水平的矩阵
(add<-matrix1+matrix2)#矩阵相加
### 1.创建数据框 ###
# 读入一个txt,csv等格式数据,即自成一个数据框
movie <- read.csv("./data/top250.csv", fileEncoding = "gbk", stringsAsFactors = F)
class(movie)
# 自己创建
director <- c("陈凯歌", "宫崎骏", "李廷香","詹姆斯·卡梅隆", "刘镇伟", "周星驰", "李安", "姜文", "张艺谋", "吴宇森","岩井俊二", "王家卫", "陈可辛"  )
birthyear <- c(1952,1941,1964,1954,1952,1962,1954,1963,1950,1946,1963,1958,1962)
gender <- c("男", "男", "女", "男", "男", "男", "男", "男", "男", "男", "男", "男", "男")
directors <- data.frame(director, birthyear, gender); head(directors)
library(reshape2)
## (1) 宽表变长表 ##
mWide = data.frame(Name = c("A", "B"), Type = c("喜剧", "动作"),
GF2018 = c(6.5, 8.0), GF2019 = c(7.0, 7.5), GF2020 = c(8.1, 7.3))
# 由于构造数据框时列名不可以为纯数字，在数字前添加GF
# 将列名中的GF去掉
colnames(mWide)[3:5] = gsub("GF", "", colnames(mWide)[3:5])
mWide #查看原表
(mLong = melt(mWide, id.vars = c("Name", "Type"), variable.name = "Year"))
## (2) 长表变宽表 ##
# 长表变宽表
dcast(mLong, Name + Type ~ Year)
library(reshape2)
?reshape2::melt
library(reshape2)
## (1) 宽表变长表 ##
mWide = data.frame(Name = c("A", "B"), Type = c("喜剧", "动作"),
GF2018 = c(6.5, 8.0), GF2019 = c(7.0, 7.5), GF2020 = c(8.1, 7.3))
# 由于构造数据框时列名不可以为纯数字，在数字前添加GF
# 将列名中的GF去掉
colnames(mWide)[3:5] = gsub("GF", "", colnames(mWide)[3:5])
mWide #查看原表
(mLong = reshape2::melt(mWide, id.vars = c("Name", "Type"), variable.name = "Year"))
## (2) 长表变宽表 ##
# 长表变宽表
dcast(mLong, Name + Type ~ Year)
detach("package:reshape", unload = TRUE)
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
detach("package:reshape", unload = TRUE)
detach("package:reshape", unload = TRUE)
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
library(openxlsx)          # 读取.xlsx数据
library(dplyr)             # 用导管运算
library(ggplot2)           # 画ggplot图
library(stringr)           # 处理字符串
library(purrr)             # 使用map函数
Sys.setlocale("LC_ALL", "zh_cn.utf-8")
dat = read.xlsx("./data/data_4_3.xlsx")                                                         # 原始数据
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
setwd("~/Desktop/renyimeng/RUC硕士/2020FALL/统计基础")
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
# 清除工作环境
cat("\014")
rm(list=ls())
dat0 <- read.csv("./data/house.csv",header=T,fileEncoding = "utf-8") #读入数据
# 处理厅数
n=dim(dat0)[1]
style=rep("其他",n)
style[which(dat0$halls==0)]="无厅"
style[which(dat0$halls>0)]="有厅"
style=factor(style,levels=c("无厅","有厅"))
dat0 <- cbind(dat0,style)
lm1 <- lm(price~CATE+school+subway+style+floor+bedrooms+AREA,data=dat0)
summary(lm1)            #回归结果展示
par(mfrow=c(2,2))           #画2*2的图
plot(lm1,which=c(1:4))      #模型诊断图，存在异方差现象，对因变量取对数
bookdown::render_book('index.Rmd', 'bookdown::gitbook')
